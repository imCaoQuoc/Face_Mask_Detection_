{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT NECESSARY PAKAGES**"
      ],
      "metadata": {
        "id": "edrnmw2F9TFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOl9PXho9ORP"
      },
      "outputs": [],
      "source": [
        "## Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, Input, AveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILDING MODEL**"
      ],
      "metadata": {
        "id": "M-0CMEsS_Qz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using pre-trained model\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5hY27Kjzhgu",
        "outputId": "f898fd7a-8dfe-4981-93af-edba75692816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define class Model\n",
        "class Model(tf.keras.models.Sequential):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "    for layer in self.model.layers:\n",
        "      self.model.layer.trainable = False\n",
        "    self.model.add(baseModel)\n",
        "    self.model.add(AveragePooling2D(pool_size=(7, 7)))\n",
        "    self.model.add(Flatten())\n",
        "    self.model.add(Dense(128, activation= 'relu'))\n",
        "    self.model.add(Dropout(0.5))\n",
        "    self.model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "  def summary(self):\n",
        "    return self.model.summary()\n",
        "\n",
        "  def compile(self):\n",
        "    self.model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics =[\"accuracy\"])\n",
        "\n",
        "  def fit(self, datagen, X_train, y_train, X_test, y_test, epoch):\n",
        "    self.model.fit(datagen.flow(X_train, y_train, batch_size=32),steps_per_epoch=len(X_train) // 32,validation_data=(X_test, y_test),validation_steps=len(X_test) // 32,epochs=epoch)\n",
        "\n",
        "  def evaluate(self, X_test, y_test):\n",
        "    evaluation = self.model.evaluate(X_test, y_test)\n",
        "    print(\"Total loss: \", evaluation[0])\n",
        "    print(\"Model accuracy: \", evaluation[1])\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    return self.model.predict(X_test)\n",
        "\n",
        "  def save(self, name= \"model\"):\n",
        "    self.model.save(f\"{name}.h5\")"
      ],
      "metadata": {
        "id": "fS0VJpdupSex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PROCESSING DATA**"
      ],
      "metadata": {
        "id": "0yec1Bbym5_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "label = []"
      ],
      "metadata": {
        "id": "UGqeP3PJoYi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to dataset\n",
        "path = \"/content/drive/MyDrive/IE221/project/data\""
      ],
      "metadata": {
        "id": "ntMDLWEJm9Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing data, read and convert image to array\n",
        "for dir in os.listdir(path):\n",
        "  data_path = os.path.join(path, dir)\n",
        "  for img in tqdm(os.listdir(data_path)):\n",
        "    img_path = os.path.join(data_path, img)\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    data.append(img)\n",
        "    label.append(dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqpUl5binOm8",
        "outputId": "dee505b5-72e4-47c0-a6bd-a5aed5e4d031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 520/1915 [00:33<00:16, 83.45it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "100%|██████████| 1915/1915 [00:43<00:00, 43.94it/s]\n",
            "100%|██████████| 1918/1918 [00:33<00:00, 56.47it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform label\n",
        "lb = LabelBinarizer()\n",
        "label = lb.fit_transform(label)\n",
        "label = to_categorical(label)"
      ],
      "metadata": {
        "id": "4LCygR9qpWu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(label)"
      ],
      "metadata": {
        "id": "Odfvh_OBp5UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
      ],
      "metadata": {
        "id": "7UqKn8qnqFWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=20,zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15,horizontal_flip=True,fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "YwL_jG3ZrXuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING DATA**"
      ],
      "metadata": {
        "id": "_QGFC3syzfoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "TjyJR21OzFE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build()"
      ],
      "metadata": {
        "id": "n1pPYQcQzVeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile()"
      ],
      "metadata": {
        "id": "JkHDumJZzX3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(datagen, X_train, y_train, X_test, y_test, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y0zKc2wzX7_",
        "outputId": "7bf4faf3-da1e-4457-fb1b-9a59c9588d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "95/95 [==============================] - 94s 461ms/step - loss: 0.1328 - accuracy: 0.9591 - val_loss: 0.6583 - val_accuracy: 0.9413\n",
            "Epoch 2/30\n",
            "95/95 [==============================] - 38s 403ms/step - loss: 0.0596 - accuracy: 0.9842 - val_loss: 0.4128 - val_accuracy: 0.9661\n",
            "Epoch 3/30\n",
            "95/95 [==============================] - 39s 410ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 0.8259 - val_accuracy: 0.9309\n",
            "Epoch 4/30\n",
            "95/95 [==============================] - 39s 408ms/step - loss: 0.0723 - accuracy: 0.9792 - val_loss: 3.2018 - val_accuracy: 0.8422\n",
            "Epoch 5/30\n",
            "95/95 [==============================] - 38s 395ms/step - loss: 0.0707 - accuracy: 0.9786 - val_loss: 2.2712 - val_accuracy: 0.7392\n",
            "Epoch 6/30\n",
            "95/95 [==============================] - 38s 395ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.7821 - val_accuracy: 0.9257\n",
            "Epoch 7/30\n",
            "95/95 [==============================] - 40s 417ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 8.0732 - val_accuracy: 0.5997\n",
            "Epoch 8/30\n",
            "95/95 [==============================] - 40s 416ms/step - loss: 0.0331 - accuracy: 0.9908 - val_loss: 0.6724 - val_accuracy: 0.9257\n",
            "Epoch 9/30\n",
            "95/95 [==============================] - 40s 420ms/step - loss: 0.0528 - accuracy: 0.9852 - val_loss: 3.4409 - val_accuracy: 0.6910\n",
            "Epoch 10/30\n",
            "95/95 [==============================] - 40s 420ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.9061 - val_accuracy: 0.9244\n",
            "Epoch 11/30\n",
            "95/95 [==============================] - 38s 399ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.5749 - val_accuracy: 0.9674\n",
            "Epoch 12/30\n",
            "95/95 [==============================] - 38s 401ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 8.1139 - val_accuracy: 0.8201\n",
            "Epoch 13/30\n",
            "95/95 [==============================] - 37s 389ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 1.2535 - val_accuracy: 0.9100\n",
            "Epoch 14/30\n",
            "95/95 [==============================] - 39s 404ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 3.4415 - val_accuracy: 0.8044\n",
            "Epoch 15/30\n",
            "95/95 [==============================] - 38s 402ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4560 - val_accuracy: 0.9687\n",
            "Epoch 16/30\n",
            "95/95 [==============================] - 39s 407ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 2.8729 - val_accuracy: 0.8853\n",
            "Epoch 17/30\n",
            "95/95 [==============================] - 39s 409ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 8.8435 - val_accuracy: 0.7275\n",
            "Epoch 18/30\n",
            "95/95 [==============================] - 38s 397ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 1.1527 - val_accuracy: 0.9544\n",
            "Epoch 19/30\n",
            "95/95 [==============================] - 39s 413ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 3.5584 - val_accuracy: 0.8683\n",
            "Epoch 20/30\n",
            "95/95 [==============================] - 39s 406ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 3.8934 - val_accuracy: 0.8044\n",
            "Epoch 21/30\n",
            "95/95 [==============================] - 38s 400ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.1755 - val_accuracy: 0.9844\n",
            "Epoch 22/30\n",
            "95/95 [==============================] - 37s 388ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 1.0591 - val_accuracy: 0.9192\n",
            "Epoch 23/30\n",
            "95/95 [==============================] - 39s 410ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.2148 - val_accuracy: 0.9739\n",
            "Epoch 24/30\n",
            "95/95 [==============================] - 39s 406ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.3381 - val_accuracy: 0.9622\n",
            "Epoch 25/30\n",
            "95/95 [==============================] - 38s 403ms/step - loss: 0.0277 - accuracy: 0.9944 - val_loss: 0.2601 - val_accuracy: 0.9831\n",
            "Epoch 26/30\n",
            "95/95 [==============================] - 37s 389ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.5118 - val_accuracy: 0.9622\n",
            "Epoch 27/30\n",
            "95/95 [==============================] - 38s 395ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 1.3090 - val_accuracy: 0.9205\n",
            "Epoch 28/30\n",
            "95/95 [==============================] - 38s 393ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.3236 - val_accuracy: 0.9726\n",
            "Epoch 29/30\n",
            "95/95 [==============================] - 39s 407ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.8698 - val_accuracy: 0.9335\n",
            "Epoch 30/30\n",
            "95/95 [==============================] - 39s 405ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.9078 - val_accuracy: 0.9387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phxb7nD6Qy3",
        "outputId": "bec1e1e6-2b85-4e9e-b34a-36dce43b4a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 3s 108ms/step - loss: 0.9078 - accuracy: 0.9387\n",
            "Total loss:  0.9077818989753723\n",
            "Model accuracy:  0.9387223124504089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlC688kS6boJ",
        "outputId": "b0c7cd04-a111-41c1-a403-32d6b9562330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.argmax(axis=1), pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY3pV5zk6iA2",
        "outputId": "2d622456-0615-4868-cc77-9fcc08e02ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93       383\n",
            "           1       0.89      1.00      0.94       384\n",
            "\n",
            "    accuracy                           0.94       767\n",
            "   macro avg       0.95      0.94      0.94       767\n",
            "weighted avg       0.95      0.94      0.94       767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"MobileNet\")"
      ],
      "metadata": {
        "id": "k74KHAz_6UWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5FvEY3q7CCf",
        "outputId": "8f8338d6-9f43-4a66-93ff-f934449e2dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 1, 1280)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               163968    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,422,210\n",
            "Trainable params: 2,388,098\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}